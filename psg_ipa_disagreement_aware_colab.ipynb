{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b66fcd",
   "metadata": {},
   "source": [
    "# PSG-IPA Disagreement-Aware Sleep Scoring (Colab)\n",
    "\n",
    "This notebook builds a practical sleep-scoring workflow on top of the PSG-IPA dataset:\n",
    "\n",
    "1. Train a sleep stage classifier from raw PSG features.\n",
    "2. Quantify inter-scorer disagreement per epoch.\n",
    "3. Train an ambiguity model to predict when epochs are likely contentious.\n",
    "4. Combine model confidence + ambiguity risk to decide:\n",
    "   - **Auto-accept** (high-confidence, low-risk)\n",
    "   - **Send to human review** (uncertain or high-risk)\n",
    "\n",
    "The goal is not only accuracy, but a **safe semi-automation pipeline** that knows when to ask for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa253ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup note\n",
    "# Dependencies are installed externally before execution in this local run.\n",
    "print('Dependency install cell skipped (already installed in current environment).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c42cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import math\n",
    "import shutil\n",
    "import pathlib\n",
    "import requests\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import mne\n",
    "import pyedflib\n",
    "from scipy.signal import welch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    cohen_kappa_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Paths\n",
    "# Use /content in Colab, and a local folder when running elsewhere.\n",
    "if 'google.colab' in str(os.environ.get('COLAB_RELEASE_TAG', '')) or pathlib.Path('/content').exists():\n",
    "    base_root = pathlib.Path('/content')\n",
    "else:\n",
    "    base_root = pathlib.Path.cwd()\n",
    "\n",
    "PROJECT_DIR = base_root / 'psg_ipa_project'\n",
    "DATA_DIR = PROJECT_DIR / 'data'\n",
    "RESULTS_DIR = PROJECT_DIR / 'results'\n",
    "for p in [PROJECT_DIR, DATA_DIR, RESULTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_URL = 'https://physionet.org/files/psg-ipa/1.0.0'\n",
    "TASK_FOLDER = 'Sleep_stages'\n",
    "TASK_ID = 'SleepStages'  # matches file naming in this task\n",
    "\n",
    "print('Project directory:', PROJECT_DIR)\n",
    "print('Data directory   :', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, out_path: pathlib.Path):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        return\n",
    "    r = requests.get(url, stream=True, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    with open(out_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "def list_remote_records(task_folder: str):\n",
    "    # PhysioNet provides a single top-level RECORDS file.\n",
    "    records_url = f\"{BASE_URL}/RECORDS\"\n",
    "    txt = requests.get(records_url, timeout=60).text\n",
    "    lines = [ln.strip() for ln in txt.splitlines() if ln.strip()]\n",
    "    raw_edf = [ln for ln in lines if ln.startswith(f\"{task_folder}/PSG/\") and ln.endswith('.edf')]\n",
    "    return sorted(raw_edf)\n",
    "\n",
    "\n",
    "def list_directory_files(url: str):\n",
    "    # Parse simple directory index pages exposed by PhysioNet.\n",
    "    html = requests.get(url, timeout=60).text\n",
    "    links = re.findall(r'href=\"([^\"]+)\"', html)\n",
    "    out = []\n",
    "    for link in links:\n",
    "        if link in ('../',):\n",
    "            continue\n",
    "        if link.endswith('/'):\n",
    "            continue\n",
    "        out.append(link)\n",
    "    return sorted(out)\n",
    "\n",
    "\n",
    "def parse_stage_label(text: str):\n",
    "    t = str(text).strip().lower()\n",
    "    # Typical EDF+ stage descriptions\n",
    "    mapping = {\n",
    "        'sleep stage w': 'W',\n",
    "        'sleep stage n1': 'N1',\n",
    "        'sleep stage n2': 'N2',\n",
    "        'sleep stage n3': 'N3',\n",
    "        'sleep stage r': 'R',\n",
    "        'sleep stage ?': 'UNK'\n",
    "    }\n",
    "    if t in mapping:\n",
    "        return mapping[t]\n",
    "\n",
    "    # Fallbacks if labels are abbreviated\n",
    "    short_map = {\n",
    "        'w': 'W', 'wake': 'W',\n",
    "        'n1': 'N1', 's1': 'N1',\n",
    "        'n2': 'N2', 's2': 'N2',\n",
    "        'n3': 'N3', 's3': 'N3', 's4': 'N3',\n",
    "        'r': 'R', 'rem': 'R'\n",
    "    }\n",
    "    t2 = re.sub(r'[^a-z0-9?]+', '', t)\n",
    "    return short_map.get(t2, 'UNK')\n",
    "\n",
    "\n",
    "def read_edf_annotations(edf_path: pathlib.Path):\n",
    "    # Returns dataframe: onset_sec, duration_sec, label\n",
    "    f = pyedflib.EdfReader(str(edf_path))\n",
    "    onsets, durations, texts = f.readAnnotations()\n",
    "    f.close()\n",
    "    df = pd.DataFrame({\n",
    "        'onset_sec': np.asarray(onsets, dtype=float),\n",
    "        'duration_sec': np.asarray(durations, dtype=float),\n",
    "        'label': [str(t) for t in texts]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_lights_window(ann_df: pd.DataFrame):\n",
    "    # Search common variants in annotation text\n",
    "    low = ann_df['label'].str.lower()\n",
    "    off_mask = low.str.contains('lights?\\s*off')\n",
    "    on_mask = low.str.contains('lights?\\s*on')\n",
    "\n",
    "    if off_mask.any() and on_mask.any():\n",
    "        t_off = float(ann_df.loc[off_mask, 'onset_sec'].min())\n",
    "        t_on = float(ann_df.loc[on_mask, 'onset_sec'].max())\n",
    "        if t_on > t_off:\n",
    "            return t_off, t_on\n",
    "\n",
    "    # fallback to full recording span covered by annotations\n",
    "    t0 = float(ann_df['onset_sec'].min())\n",
    "    t1 = float((ann_df['onset_sec'] + ann_df['duration_sec'].clip(lower=0)).max())\n",
    "    return t0, t1\n",
    "\n",
    "\n",
    "def stage_timeline_from_annotations(ann_df: pd.DataFrame, epoch_sec=30):\n",
    "    df = ann_df.copy()\n",
    "    df['stage'] = df['label'].map(parse_stage_label)\n",
    "    stage_df = df[df['stage'] != 'UNK'].copy()\n",
    "    if stage_df.empty:\n",
    "        return pd.DataFrame(columns=['epoch_idx', 'stage'])\n",
    "\n",
    "    t_start, t_end = get_lights_window(ann_df)\n",
    "    n_epochs = int(math.floor((t_end - t_start) / epoch_sec))\n",
    "    epochs = []\n",
    "\n",
    "    # For each epoch, assign stage with maximum overlap\n",
    "    for e in range(n_epochs):\n",
    "        e0 = t_start + e * epoch_sec\n",
    "        e1 = e0 + epoch_sec\n",
    "\n",
    "        overlaps = []\n",
    "        for _, row in stage_df.iterrows():\n",
    "            a0 = float(row['onset_sec'])\n",
    "            a1 = float(row['onset_sec'] + max(row['duration_sec'], 0.0))\n",
    "            ov = max(0.0, min(e1, a1) - max(e0, a0))\n",
    "            if ov > 0:\n",
    "                overlaps.append((ov, row['stage']))\n",
    "\n",
    "        if len(overlaps) == 0:\n",
    "            epochs.append((e, 'UNK'))\n",
    "        else:\n",
    "            overlaps.sort(reverse=True, key=lambda x: x[0])\n",
    "            epochs.append((e, overlaps[0][1]))\n",
    "\n",
    "    return pd.DataFrame(epochs, columns=['epoch_idx', 'stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sleep staging PSG + manual expert annotation EDF files.\n",
    "# This avoids full-dataset download while keeping enough data for the pipeline.\n",
    "MAX_RECORDINGS = 1\n",
    "\n",
    "raw_records = list_remote_records(TASK_FOLDER)[:MAX_RECORDINGS]\n",
    "selected_sn = [re.findall(r'(SN\\d+)_SleepStages\\.edf', pathlib.Path(r).name)[0] for r in raw_records]\n",
    "print('Selected recordings:', selected_sn)\n",
    "\n",
    "# Build annotation file list from PhysioNet directory index.\n",
    "manual_ann_names = list_directory_files(f\"{BASE_URL}/{TASK_FOLDER}/Annotations/manual/\")\n",
    "manual_ann_edf = [n for n in manual_ann_names if n.endswith('.edf') and any(n.startswith(sn + '_SleepStages_manual_') for sn in selected_sn)]\n",
    "\n",
    "selected_files = raw_records + [f\"{TASK_FOLDER}/Annotations/manual/{n}\" for n in manual_ann_edf]\n",
    "print('Files to download:', len(selected_files))\n",
    "\n",
    "for rel in tqdm(selected_files):\n",
    "    src = f\"{BASE_URL}/{rel}\"\n",
    "    dst = DATA_DIR / rel\n",
    "    download_file(src, dst)\n",
    "\n",
    "print('Download done. Local task path:', DATA_DIR / TASK_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE_TO_INT = {'W': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'R': 4}\n",
    "INT_TO_STAGE = {v: k for k, v in STAGE_TO_INT.items()}\n",
    "\n",
    "\n",
    "def pick_channels(raw: mne.io.BaseRaw):\n",
    "    # Try common names from AASM-style montages.\n",
    "    wanted = ['F4-M1', 'C4-M1', 'Cz-M1', 'O2-M1', 'E1-M2', 'E2-M2', 'EMG chin', 'EMGchin']\n",
    "    chosen = []\n",
    "    for ch in wanted:\n",
    "        if ch in raw.ch_names:\n",
    "            chosen.append(ch)\n",
    "    if len(chosen) == 0:\n",
    "        # Fallback: keep first 6 channels if naming differs.\n",
    "        chosen = raw.ch_names[:6]\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def epoch_features_from_raw(raw_path: pathlib.Path, n_epochs: int, epoch_sec=30):\n",
    "    raw = mne.io.read_raw_edf(str(raw_path), preload=True, verbose='ERROR')\n",
    "    chs = pick_channels(raw)\n",
    "    raw.pick(chs)\n",
    "\n",
    "    # Standardize sample rate for stable feature extraction.\n",
    "    target_sfreq = 100.0\n",
    "    if raw.info['sfreq'] != target_sfreq:\n",
    "        raw.resample(target_sfreq)\n",
    "\n",
    "    sf = raw.info['sfreq']\n",
    "    data = raw.get_data()  # shape: channels x samples\n",
    "    epoch_len = int(epoch_sec * sf)\n",
    "\n",
    "    feats = []\n",
    "    max_epochs = min(n_epochs, data.shape[1] // epoch_len)\n",
    "\n",
    "    # Frequency bands for EEG-like channels\n",
    "    bands = {\n",
    "        'delta': (0.5, 4.0),\n",
    "        'theta': (4.0, 8.0),\n",
    "        'alpha': (8.0, 12.0),\n",
    "        'sigma': (12.0, 16.0),\n",
    "        'beta': (16.0, 30.0)\n",
    "    }\n",
    "\n",
    "    for e in range(max_epochs):\n",
    "        s0 = e * epoch_len\n",
    "        s1 = s0 + epoch_len\n",
    "        x = data[:, s0:s1]\n",
    "\n",
    "        row = {'epoch_idx': e}\n",
    "        for ci, ch_name in enumerate(chs):\n",
    "            sig = x[ci]\n",
    "            row[f'{ch_name}_mean'] = float(np.mean(sig))\n",
    "            row[f'{ch_name}_std'] = float(np.std(sig))\n",
    "            row[f'{ch_name}_rms'] = float(np.sqrt(np.mean(sig ** 2)))\n",
    "\n",
    "            f, pxx = welch(sig, fs=sf, nperseg=min(512, len(sig)))\n",
    "            total = np.trapezoid(pxx[(f >= 0.5) & (f <= 30.0)], f[(f >= 0.5) & (f <= 30.0)]) + 1e-12\n",
    "            for b, (lo, hi) in bands.items():\n",
    "                m = (f >= lo) & (f < hi)\n",
    "                bp = np.trapezoid(pxx[m], f[m]) if np.any(m) else 0.0\n",
    "                row[f'{ch_name}_{b}_relpow'] = float(bp / total)\n",
    "\n",
    "        feats.append(row)\n",
    "\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "\n",
    "def scorer_tables_for_record(task_dir: pathlib.Path, sn: str, setting: str = 'manual'):\n",
    "    # setting in {'manual', 'semiauto'} for Sleep_stages scorer files.\n",
    "    patt = str(task_dir / '**' / f'{sn}_SleepStages_{setting}_scorer*.edf')\n",
    "    files = sorted(glob.glob(patt, recursive=True))\n",
    "    out = {}\n",
    "    for fp in files:\n",
    "        m = re.search(r'scorer(\\d+)', fp)\n",
    "        scorer_id = int(m.group(1)) if m else -1\n",
    "        ann = read_edf_annotations(pathlib.Path(fp))\n",
    "        tl = stage_timeline_from_annotations(ann, epoch_sec=30)\n",
    "        out[scorer_id] = tl\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74802c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dir = DATA_DIR / TASK_FOLDER\n",
    "raw_files = sorted(task_dir.glob('PSG/SN*_SleepStages.edf'))\n",
    "print('Raw files found:', [p.name for p in raw_files])\n",
    "\n",
    "rows = []\n",
    "for raw_fp in tqdm(raw_files):\n",
    "    sn = re.findall(r'(SN\\d+)_SleepStages\\.edf', raw_fp.name)[0]\n",
    "\n",
    "    scorer_tl = scorer_tables_for_record(task_dir, sn, setting='manual')\n",
    "    if len(scorer_tl) < 2:\n",
    "        print(f'Skipping {sn}: not enough scorer files.')\n",
    "        continue\n",
    "\n",
    "    scorer_ids = sorted(scorer_tl.keys())\n",
    "    ref_scorer = scorer_ids[0]\n",
    "\n",
    "    # Align scorers by epoch index\n",
    "    per_epoch_votes = {}\n",
    "    per_epoch_by_scorer = {}\n",
    "    for scorer_id, tl in scorer_tl.items():\n",
    "        for _, r in tl.iterrows():\n",
    "            e = int(r['epoch_idx'])\n",
    "            st = r['stage']\n",
    "            if st == 'UNK' or st not in STAGE_TO_INT:\n",
    "                continue\n",
    "            per_epoch_votes.setdefault(e, []).append(st)\n",
    "            per_epoch_by_scorer.setdefault(e, {})[scorer_id] = st\n",
    "\n",
    "    if len(per_epoch_votes) == 0:\n",
    "        print(f'Skipping {sn}: no valid epoch labels.')\n",
    "        continue\n",
    "\n",
    "    n_epochs = max(per_epoch_votes.keys()) + 1\n",
    "    feat_df = epoch_features_from_raw(raw_fp, n_epochs=n_epochs, epoch_sec=30)\n",
    "\n",
    "    for _, fr in feat_df.iterrows():\n",
    "        e = int(fr['epoch_idx'])\n",
    "        labels = per_epoch_votes.get(e, [])\n",
    "        if len(labels) < 2:\n",
    "            continue\n",
    "\n",
    "        vc = pd.Series(labels).value_counts()\n",
    "        consensus = vc.index[0]\n",
    "        agree_frac = vc.iloc[0] / vc.sum()\n",
    "        disagreement = 1.0 - agree_frac\n",
    "\n",
    "        ref_stage = per_epoch_by_scorer.get(e, {}).get(ref_scorer, None)\n",
    "\n",
    "        row = {\n",
    "            'record_id': sn,\n",
    "            'epoch_idx': e,\n",
    "            'consensus_stage': consensus,\n",
    "            'y_stage': STAGE_TO_INT[consensus],\n",
    "            'agreement_frac': float(agree_frac),\n",
    "            'disagreement': float(disagreement),\n",
    "            'ambiguous': int(disagreement >= 0.25),\n",
    "            'n_scorers': int(vc.sum()),\n",
    "            'ref_scorer_id': int(ref_scorer),\n",
    "            'ref_scorer_stage': ref_stage if ref_stage is not None else 'UNK',\n",
    "            'ref_scorer_y': STAGE_TO_INT[ref_stage] if ref_stage in STAGE_TO_INT else -1,\n",
    "        }\n",
    "        row.update(fr.drop(labels=['epoch_idx']).to_dict())\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print('Dataset shape:', df.shape)\n",
    "print(df[['record_id', 'epoch_idx', 'consensus_stage', 'disagreement']].head())\n",
    "\n",
    "out_csv = RESULTS_DIR / 'epoch_level_dataset.csv'\n",
    "df.to_csv(out_csv, index=False)\n",
    "print('Saved:', out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a79c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks\n",
    "print(df['consensus_stage'].value_counts(normalize=True).round(3))\n",
    "print('\\nDisagreement summary:')\n",
    "print(df['disagreement'].describe().round(3))\n",
    "print('\\nAmbiguous fraction:', round(df['ambiguous'].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc82b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/evaluate with record-wise splits to avoid leakage across nights.\n",
    "meta_cols = [\n",
    "    'record_id', 'epoch_idx', 'consensus_stage', 'y_stage',\n",
    "    'agreement_frac', 'disagreement', 'ambiguous', 'n_scorers',\n",
    "    'ref_scorer_id', 'ref_scorer_stage', 'ref_scorer_y',\n",
    "]\n",
    "feature_cols = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "X = df[feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0).values\n",
    "y_stage = df['y_stage'].values\n",
    "y_amb = df['ambiguous'].values\n",
    "groups = df['record_id'].values\n",
    "n_groups = len(np.unique(groups))\n",
    "\n",
    "# Base classifiers\n",
    "stage_base = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "amb_base = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced_subsample'\n",
    ")\n",
    "\n",
    "oof_stage_pred = np.zeros(len(df), dtype=int)\n",
    "oof_stage_conf = np.zeros(len(df), dtype=float)\n",
    "oof_amb_risk = np.zeros(len(df), dtype=float)\n",
    "\n",
    "if n_groups >= 2:\n",
    "    # Calibrate stage probabilities for more meaningful confidence.\n",
    "    stage_clf = CalibratedClassifierCV(stage_base, method='sigmoid', cv=3)\n",
    "    amb_clf = CalibratedClassifierCV(amb_base, method='sigmoid', cv=3)\n",
    "\n",
    "    cv = GroupKFold(n_splits=min(5, n_groups))\n",
    "    for fold, (tr, te) in enumerate(cv.split(X, y_stage, groups), 1):\n",
    "        Xtr, Xte = X[tr], X[te]\n",
    "        ytr_stage, yte_stage = y_stage[tr], y_stage[te]\n",
    "        ytr_amb = y_amb[tr]\n",
    "\n",
    "        stage_clf.fit(Xtr, ytr_stage)\n",
    "        amb_clf.fit(Xtr, ytr_amb)\n",
    "\n",
    "        proba_stage = stage_clf.predict_proba(Xte)\n",
    "        pred_stage = np.argmax(proba_stage, axis=1)\n",
    "        conf_stage = np.max(proba_stage, axis=1)\n",
    "\n",
    "        risk_amb = amb_clf.predict_proba(Xte)[:, 1]\n",
    "\n",
    "        oof_stage_pred[te] = pred_stage\n",
    "        oof_stage_conf[te] = conf_stage\n",
    "        oof_amb_risk[te] = risk_amb\n",
    "\n",
    "        fold_acc = accuracy_score(yte_stage, pred_stage)\n",
    "        print(f'Fold {fold} stage accuracy: {fold_acc:.3f}')\n",
    "else:\n",
    "    print('Only one unique record_id found; using in-sample fallback evaluation.')\n",
    "    stage_base.fit(X, y_stage)\n",
    "    amb_base.fit(X, y_amb)\n",
    "\n",
    "    proba_stage = stage_base.predict_proba(X)\n",
    "    oof_stage_pred = np.argmax(proba_stage, axis=1)\n",
    "    oof_stage_conf = np.max(proba_stage, axis=1)\n",
    "    oof_amb_risk = amb_base.predict_proba(X)[:, 1]\n",
    "\n",
    "stage_acc = accuracy_score(y_stage, oof_stage_pred)\n",
    "print('\\nOverall stage accuracy:', round(stage_acc, 4))\n",
    "print('\\nStage report:')\n",
    "print(classification_report(y_stage, oof_stage_pred, target_names=[INT_TO_STAGE[i] for i in sorted(INT_TO_STAGE)]))\n",
    "\n",
    "amb_auc = roc_auc_score(y_amb, oof_amb_risk) if len(np.unique(y_amb)) > 1 else np.nan\n",
    "print('Ambiguity ROC-AUC:', round(float(amb_auc), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human-in-the-loop triage policy\n",
    "# Accept automatically only if stage confidence is high AND ambiguity risk is low.\n",
    "CONF_THRESH = 0.80\n",
    "AMB_RISK_THRESH = 0.40\n",
    "\n",
    "auto_accept = (oof_stage_conf >= CONF_THRESH) & (oof_amb_risk <= AMB_RISK_THRESH)\n",
    "manual_review = ~auto_accept\n",
    "\n",
    "coverage = auto_accept.mean()\n",
    "acc_all = accuracy_score(y_stage, oof_stage_pred)\n",
    "acc_auto = accuracy_score(y_stage[auto_accept], oof_stage_pred[auto_accept]) if auto_accept.any() else np.nan\n",
    "\n",
    "print(f'Coverage (auto-accepted epochs): {coverage:.3f}')\n",
    "print(f'Accuracy on all epochs         : {acc_all:.3f}')\n",
    "print(f'Accuracy on auto-accepted only : {acc_auto:.3f}')\n",
    "print(f'Fraction sent to human review  : {manual_review.mean():.3f}')\n",
    "\n",
    "policy_df = df[['record_id', 'epoch_idx', 'consensus_stage', 'disagreement']].copy()\n",
    "policy_df['pred_stage'] = [INT_TO_STAGE[i] for i in oof_stage_pred]\n",
    "policy_df['stage_confidence'] = oof_stage_conf\n",
    "policy_df['ambiguity_risk'] = oof_amb_risk\n",
    "policy_df['auto_accept'] = auto_accept.astype(int)\n",
    "policy_df['needs_human_review'] = manual_review.astype(int)\n",
    "\n",
    "policy_csv = RESULTS_DIR / 'triage_policy_output.csv'\n",
    "policy_df.to_csv(policy_csv, index=False)\n",
    "print('Saved:', policy_csv)\n",
    "policy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a19b9",
   "metadata": {},
   "source": [
    "## Paper-ready analysis additions\n",
    "\n",
    "This section adds figures and tables aligned to your manuscript goals.\n",
    "\n",
    "> Note: `MAX_RECORDINGS = 1` is currently a **pipeline sanity setting**. Results here demonstrate feasibility, not final clinical claims. For paper-grade results, increase recordings and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an analysis frame used by all plots/tables\n",
    "analysis_df = policy_df.merge(\n",
    "    df[['record_id', 'epoch_idx', 'ref_scorer_id', 'ref_scorer_stage', 'ref_scorer_y']],\n",
    "    on=['record_id', 'epoch_idx'],\n",
    "    how='left',\n",
    ")\n",
    "analysis_df['y_true'] = y_stage\n",
    "analysis_df['y_pred'] = oof_stage_pred\n",
    "analysis_df['consensus_level'] = np.where(analysis_df['disagreement'] < 0.10, 'High-consensus', 'Low-consensus')\n",
    "analysis_df['accept_score'] = analysis_df['stage_confidence'] * (1.0 - analysis_df['ambiguity_risk'])\n",
    "\n",
    "print('Rows:', len(analysis_df))\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c899eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Disagreement heatmap over the whole night\n",
    "hm = analysis_df.pivot(index='record_id', columns='epoch_idx', values='disagreement').sort_index()\n",
    "\n",
    "plt.figure(figsize=(14, max(2.5, 1.2 * len(hm))))\n",
    "sns.heatmap(hm, cmap='magma', vmin=0, vmax=1, cbar_kws={'label': 'Disagreement'})\n",
    "plt.title('Inter-scorer disagreement heatmap across night')\n",
    "plt.xlabel('Epoch (30s)')\n",
    "plt.ylabel('Recording')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c99616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Hypnogram + disagreement overlay\n",
    "rec0 = analysis_df['record_id'].iloc[0]\n",
    "plot_df = analysis_df[analysis_df['record_id'] == rec0].sort_values('epoch_idx').copy()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.step(plot_df['epoch_idx'], plot_df['y_true'], where='post', label='Consensus hypnogram', linewidth=2)\n",
    "plt.scatter(plot_df['epoch_idx'], plot_df['y_true'], c=plot_df['disagreement'], cmap='coolwarm', s=20, label='Disagreement intensity')\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Disagreement')\n",
    "\n",
    "plt.yticks(list(INT_TO_STAGE.keys()), [INT_TO_STAGE[i] for i in sorted(INT_TO_STAGE)])\n",
    "plt.gca().invert_yaxis()  # conventional hypnogram orientation\n",
    "plt.title(f'Hypnogram with disagreement overlay ({rec0})')\n",
    "plt.xlabel('Epoch (30s)')\n",
    "plt.ylabel('Stage')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Risk-Coverage curve (core selective prediction proof)\n",
    "curve = []\n",
    "ranked = analysis_df.sort_values('accept_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "for cov in np.linspace(0.10, 1.00, 19):\n",
    "    k = max(1, int(round(cov * len(ranked))))\n",
    "    kept = ranked.iloc[:k]\n",
    "    acc_kept = accuracy_score(kept['y_true'], kept['y_pred'])\n",
    "    risk_kept = 1.0 - acc_kept\n",
    "    curve.append({'coverage': k / len(ranked), 'risk': risk_kept, 'accuracy': acc_kept})\n",
    "\n",
    "curve_df = pd.DataFrame(curve)\n",
    "\n",
    "plt.figure(figsize=(6.5, 4.5))\n",
    "plt.plot(curve_df['coverage'], curve_df['risk'], marker='o', label='Selective model risk')\n",
    "plt.axhline(1.0 - accuracy_score(analysis_df['y_true'], analysis_df['y_pred']), linestyle='--', color='gray', label='Auto-only risk')\n",
    "plt.xlabel('Coverage (fraction auto-accepted)')\n",
    "plt.ylabel('Risk = 1 - accuracy (on accepted set)')\n",
    "plt.title('Risk-Coverage curve')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "curve_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Model confidence vs human disagreement scatter\n",
    "plt.figure(figsize=(6.5, 5))\n",
    "sns.scatterplot(\n",
    "    data=analysis_df,\n",
    "    x='stage_confidence',\n",
    "    y='disagreement',\n",
    "    hue='auto_accept',\n",
    "    palette={0: 'tab:red', 1: 'tab:green'},\n",
    "    alpha=0.75,\n",
    "    s=45,\n",
    ")\n",
    "plt.title('Model confidence vs human disagreement')\n",
    "plt.xlabel('Model confidence')\n",
    "plt.ylabel('Inter-scorer disagreement')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Confusion matrix split into high-consensus vs low-consensus epochs\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "label_names = [INT_TO_STAGE[i] for i in labels]\n",
    "\n",
    "high_df = analysis_df[analysis_df['consensus_level'] == 'High-consensus']\n",
    "low_df = analysis_df[analysis_df['consensus_level'] == 'Low-consensus']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4.8), sharey=True)\n",
    "for ax, sub_df, title in [\n",
    "    (axes[0], high_df, 'High-consensus'),\n",
    "    (axes[1], low_df, 'Low-consensus'),\n",
    "]:\n",
    "    if len(sub_df) == 0:\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{title} (no samples)')\n",
    "        continue\n",
    "    cm = confusion_matrix(sub_df['y_true'], sub_df['y_pred'], labels=labels)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)\n",
    "    ax.set_xticklabels(label_names)\n",
    "    ax.set_yticklabels(label_names, rotation=0)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(f'{title} (n={len(sub_df)})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A + B) Practical workflow comparison and simulated lab time savings\n",
    "# Time model in normalized units per epoch.\n",
    "T_HUMAN = 1.00\n",
    "T_AUTO = 0.08\n",
    "\n",
    "valid_ref = analysis_df[analysis_df['ref_scorer_y'] >= 0].copy()\n",
    "\n",
    "def safe_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred) if len(np.unique(y_true)) > 1 else np.nan\n",
    "\n",
    "# Human-only baseline: one scorer as proxy for routine human scoring\n",
    "human_acc = accuracy_score(valid_ref['y_true'], valid_ref['ref_scorer_y']) if len(valid_ref) else np.nan\n",
    "human_f1 = f1_score(valid_ref['y_true'], valid_ref['ref_scorer_y'], average='macro') if len(valid_ref) else np.nan\n",
    "human_kappa = safe_kappa(valid_ref['y_true'], valid_ref['ref_scorer_y']) if len(valid_ref) else np.nan\n",
    "\n",
    "# Auto-only: no deferral\n",
    "auto_acc = accuracy_score(analysis_df['y_true'], analysis_df['y_pred'])\n",
    "auto_f1 = f1_score(analysis_df['y_true'], analysis_df['y_pred'], average='macro')\n",
    "auto_kappa = safe_kappa(analysis_df['y_true'], analysis_df['y_pred'])\n",
    "\n",
    "# Selective automation: deferred epochs are reviewed by humans (assumed corrected to consensus)\n",
    "final_pred_selective = np.where(analysis_df['auto_accept'] == 1, analysis_df['y_pred'], analysis_df['y_true'])\n",
    "sel_acc = accuracy_score(analysis_df['y_true'], final_pred_selective)\n",
    "sel_f1 = f1_score(analysis_df['y_true'], final_pred_selective, average='macro')\n",
    "sel_kappa = safe_kappa(analysis_df['y_true'], final_pred_selective)\n",
    "\n",
    "deferred = float((analysis_df['auto_accept'] == 0).mean())\n",
    "\n",
    "# Simulated time costs\n",
    "cost_human = T_HUMAN\n",
    "cost_auto = T_AUTO\n",
    "cost_selective = (1.0 - deferred) * T_AUTO + deferred * T_HUMAN\n",
    "\n",
    "workflow_table = pd.DataFrame([\n",
    "    {\n",
    "        'workflow': 'Human-only (baseline)',\n",
    "        'accuracy': human_acc,\n",
    "        'kappa': human_kappa,\n",
    "        'macro_f1': human_f1,\n",
    "        '% deferred': 100.0,\n",
    "        'estimated_time_saved_%': 0.0,\n",
    "    },\n",
    "    {\n",
    "        'workflow': 'Auto-only (no deferral)',\n",
    "        'accuracy': auto_acc,\n",
    "        'kappa': auto_kappa,\n",
    "        'macro_f1': auto_f1,\n",
    "        '% deferred': 0.0,\n",
    "        'estimated_time_saved_%': 100.0 * (1.0 - cost_auto / cost_human),\n",
    "    },\n",
    "    {\n",
    "        'workflow': 'Selective automation (proposed)',\n",
    "        'accuracy': sel_acc,\n",
    "        'kappa': sel_kappa,\n",
    "        'macro_f1': sel_f1,\n",
    "        '% deferred': 100.0 * deferred,\n",
    "        'estimated_time_saved_%': 100.0 * (1.0 - cost_selective / cost_human),\n",
    "    },\n",
    "]).round(4)\n",
    "\n",
    "workflow_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) PSG-IPA specific analysis: manual vs semi-automatic disagreement\n",
    "# Download semi-automatic scorer annotations for selected recordings.\n",
    "semiauto_ann_names = list_directory_files(f\"{BASE_URL}/{TASK_FOLDER}/Annotations/semiauto/\")\n",
    "semiauto_ann_edf = [\n",
    "    n for n in semiauto_ann_names\n",
    "    if n.endswith('.edf') and any(n.startswith(sn + '_SleepStages_semiauto_') for sn in selected_sn)\n",
    "]\n",
    "\n",
    "for n in tqdm(semiauto_ann_edf):\n",
    "    rel = f\"{TASK_FOLDER}/Annotations/semiauto/{n}\"\n",
    "    download_file(f\"{BASE_URL}/{rel}\", DATA_DIR / rel)\n",
    "\n",
    "print('Downloaded semiauto annotation files:', len(semiauto_ann_edf))\n",
    "\n",
    "\n",
    "def disagreement_by_setting(task_dir: pathlib.Path, sn_list, setting: str):\n",
    "    out = []\n",
    "    for sn in sn_list:\n",
    "        scorer_tl = scorer_tables_for_record(task_dir, sn, setting=setting)\n",
    "        if len(scorer_tl) < 2:\n",
    "            continue\n",
    "\n",
    "        per_epoch = {}\n",
    "        for scorer_id, tl in scorer_tl.items():\n",
    "            for _, r in tl.iterrows():\n",
    "                e = int(r['epoch_idx'])\n",
    "                st = r['stage']\n",
    "                if st == 'UNK' or st not in STAGE_TO_INT:\n",
    "                    continue\n",
    "                per_epoch.setdefault(e, []).append(st)\n",
    "\n",
    "        for e, labels in per_epoch.items():\n",
    "            if len(labels) < 2:\n",
    "                continue\n",
    "            vc = pd.Series(labels).value_counts()\n",
    "            disagreement = 1.0 - (vc.iloc[0] / vc.sum())\n",
    "            out.append({'record_id': sn, 'epoch_idx': e, 'setting': setting, 'disagreement': float(disagreement)})\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "man_dis = disagreement_by_setting(task_dir, selected_sn, 'manual')\n",
    "sem_dis = disagreement_by_setting(task_dir, selected_sn, 'semiauto')\n",
    "dis_compare = pd.concat([man_dis, sem_dis], ignore_index=True)\n",
    "\n",
    "print('Manual epochs   :', len(man_dis))\n",
    "print('Semi-auto epochs:', len(sem_dis))\n",
    "if len(dis_compare):\n",
    "    print(dis_compare.groupby('setting')['disagreement'].describe().round(3))\n",
    "\n",
    "plt.figure(figsize=(7, 4.5))\n",
    "if len(dis_compare):\n",
    "    sns.boxplot(data=dis_compare, x='setting', y='disagreement', showfliers=False)\n",
    "    sns.stripplot(data=dis_compare.sample(min(len(dis_compare), 300), random_state=SEED), x='setting', y='disagreement', color='black', alpha=0.35, size=3)\n",
    "plt.title('Manual vs semi-automatic inter-scorer disagreement')\n",
    "plt.xlabel('Scoring condition')\n",
    "plt.ylabel('Disagreement')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Does the model align more with manual or semiauto consensus?\n",
    "def consensus_timeline(task_dir: pathlib.Path, sn: str, setting: str):\n",
    "    scorer_tl = scorer_tables_for_record(task_dir, sn, setting=setting)\n",
    "    if len(scorer_tl) < 2:\n",
    "        return pd.DataFrame(columns=['record_id', 'epoch_idx', f'consensus_{setting}'])\n",
    "\n",
    "    per_epoch = {}\n",
    "    for _, tl in scorer_tl.items():\n",
    "        for _, r in tl.iterrows():\n",
    "            e = int(r['epoch_idx'])\n",
    "            st = r['stage']\n",
    "            if st == 'UNK' or st not in STAGE_TO_INT:\n",
    "                continue\n",
    "            per_epoch.setdefault(e, []).append(st)\n",
    "\n",
    "    rows = []\n",
    "    for e, labels in per_epoch.items():\n",
    "        vc = pd.Series(labels).value_counts()\n",
    "        rows.append({'record_id': sn, 'epoch_idx': e, f'consensus_{setting}': vc.index[0]})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "cons_man = pd.concat([consensus_timeline(task_dir, sn, 'manual') for sn in selected_sn], ignore_index=True)\n",
    "cons_sem = pd.concat([consensus_timeline(task_dir, sn, 'semiauto') for sn in selected_sn], ignore_index=True)\n",
    "\n",
    "align_df = analysis_df[['record_id', 'epoch_idx', 'pred_stage']].merge(cons_man, on=['record_id', 'epoch_idx'], how='inner')\n",
    "align_df = align_df.merge(cons_sem, on=['record_id', 'epoch_idx'], how='inner')\n",
    "\n",
    "if len(align_df):\n",
    "    align_manual = (align_df['pred_stage'] == align_df['consensus_manual']).mean()\n",
    "    align_semi = (align_df['pred_stage'] == align_df['consensus_semiauto']).mean()\n",
    "    print(f'Model agreement with manual consensus   : {align_manual:.3f}')\n",
    "    print(f'Model agreement with semiauto consensus : {align_semi:.3f}')\n",
    "else:\n",
    "    print('No overlapping epochs to compare manual vs semiauto alignment in current subset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7eec2",
   "metadata": {},
   "source": [
    "## How to adapt this notebook\n",
    "\n",
    "- **Use all PSG-IPA tasks:** repeat the pipeline for `EEG_arousals`, `Limb_movements`, and `Resp_events`, changing label parsing and epoch/event windows.\n",
    "- **Replace handcrafted features with deep models:** use 1D CNN/Transformer encoders over raw channels.\n",
    "- **Improve calibration:** try isotonic calibration and reliability diagrams.\n",
    "- **Choose policy thresholds by operations goals:** tune `CONF_THRESH` and `AMB_RISK_THRESH` to satisfy a target review workload.\n",
    "- **Clinical deployment idea:** auto-accept only low-risk segments, route high-risk segments to experts, and track post-review corrections for continual improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
